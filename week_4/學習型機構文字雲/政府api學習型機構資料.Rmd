---
title: "用R進行中文 text Mining   政府開放資料"
output: html_document
---
此次資料是 學習型機構資料集描述
連結：https://data.taipei/dataset/detail/metadata?id=ac589468-529b-4636-a9b2-ab57ae41cbcb
https://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=24c9f8fe-88db-4a6e-895c-498fbc94df94

前置作業
```{r}
#清空所有記憶體
rm(list=ls(all.names = TRUE))

#工具
library(NLP)
library(tm) #文字探勘
library(jiebaRD)
library(jiebaR) #中文斷詞 
library(RColorBrewer)
library(wordcloud) #產生文字雲

```

抓取政府開放資料api
```{r}
# Taipei api http://oops.gov.taipei/
library(jsonlite)
library(RCurl)
library(rvest)
# 學習型機構資料集描述json url

link <- url(paste('https://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=24c9f8fe-88db-4a6e-895c-498fbc94df94'))
phwash = read_html(link)
docs <- Corpus(VectorSource(phwash))



#url <- 'https://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=24c9f8fe-88db-4a6e-895c-498fbc94df94'
#jsonData<-fromJSON(getURL("https://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=24c9f8fe-88db-4a6e-895c-498fbc94df94"))
#str( jsonData)

#Get it with jsonlite package
#jsonData <- fromJSON(url, flatten = TRUE)

#Write it into csv.
#docs <-write.csv(file = 'test.csv', jsonData , fileEncoding = 'utf-8')
#docs <- read.table(docs, header = T, row.names = 1, sep = ",")
#docs <- as.matrix(docs)

```


```

開始文字處理
```{r}
#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
  return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "。")
docs <- tm_map(docs, toSpace, "，")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "至")
docs <- tm_map(docs, toSpace, "子")
docs <- tm_map(docs, toSpace, "用")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "之")
docs <- tm_map(docs, toSpace, "段號")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "用")
docs <- tm_map(docs, toSpace, "段")
docs <- tm_map(docs, toSpace, "巷")
docs <- tm_map(docs, toSpace, "號")
docs <- tm_map(docs, toSpace, "區")
docs <- tm_map(docs, toSpace, "街")
docs <- tm_map(docs, toSpace, "與")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "及")
docs <- tm_map(docs, toSpace, "士")
docs <- tm_map(docs, toSpace, "路")
docs <- tm_map(docs, toSpace, "之")
docs <- tm_map(docs, toSpace, "日")
docs <- tm_map(docs, toSpace, "中")
docs <- tm_map(docs, toSpace, "一")
docs <- tm_map(docs, toSpace, "三")
docs <- tm_map(docs, toSpace, "並")
docs <- tm_map(docs, toSpace, "使")

#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
```
進行中文斷詞：結巴字典

## R Markdown
```{r}
mixseg = worker()
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))

library("jiebaR")
Sys.setlocale(category = "LC_ALL", locale = "cht")
```
畫出關鍵字詞 文字雲
```{r}
library(wordcloud)

par(family=("HeitiTC Light"))

mixseg = worker()
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
par(family=("Heiti TC Light"))

wordcloud(freqFrame$Var1,freqFrame$Freq,
          scale=c(5,0.5),min.freq=10,max.words=55,
          random.order=FALSE, random.color=TRUE, 
          rot.per=0, colors=brewer.pal(8, "Dark2"),
          ordered.colors=FALSE,use.r.layout=FALSE,
          fixed.asp=TRUE)
```


分析觀察心得：

這份是政府學習型機構資料集描述
學習型機構，或稱 學習型組織，是指企業透過「組織學習」實現員工知識更新和保持企業創新能力理論和實踐。

發現這份文件是以台北市國民小學為主
而在內湖、北投、萬華、信義、文山區 設立比較多學習型機構
多數重視、追求的概念有
注重教育、發展、環境、多元、英文...
在教師、孩子、家長三方角色也都有特別在意能

